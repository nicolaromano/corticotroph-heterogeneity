{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from model_trainer import LabelTransferTrainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('datasets.csv')\n",
    "datasets = datasets[~datasets['study_id'].isin(['Ho2020M', 'Ho2020F'])]\n",
    "\n",
    "trainer = LabelTransferTrainer(hyperparams_file='hyperparams.csv',\n",
    "                               data_dir='exported_matrices',\n",
    "                               output_dir='label_transfer_model_output',\n",
    "                               verbose=False,\n",
    "                               random_seed=12345)\n",
    "\n",
    "trainer.save_models_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets['study_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = 'Lopez2021M'\n",
    "do_hyperparam_search = True\n",
    "single_param_search = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep through the hyperparameters of the model to find the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_hyperparameters = ['learning_rate', 'num_layers', 'num_nodes', 'reg_factor', \n",
    "#                             'reg_type', 'dropout_rate', 'bn_momentum', 'batch_size']\n",
    "\n",
    "if do_hyperparam_search:\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # We recreate the trainer object here in case we changed the hyperparams\n",
    "    trainer = LabelTransferTrainer(hyperparams_file='hyperparams.csv',\n",
    "                                      data_dir='exported_matrices',\n",
    "                                      output_dir='label_transfer_model_output',\n",
    "                                      verbose=False,\n",
    "                                      random_seed=12345)\n",
    "\n",
    "    if single_param_search:\n",
    "        # Single hyperparameter\n",
    "        param = \"bn_momentum\"\n",
    "        values = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "        \n",
    "        res = trainer.tune_hyperparam(study_id, param, values, n_folds=5)\n",
    "    else:        \n",
    "        # Two hyperparameters\n",
    "        param1 = \"bn_momentum\"\n",
    "        param2 = \"reg_factor\"\n",
    "        values1 = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "        values2 = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "        \n",
    "        res = trainer.tune_two_hyperparameters(study_id, param1, param2, values1, values2, n_folds=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n",
    "# Mean folds\n",
    "if single_param_search:\n",
    "    res_grouped = res.groupby([param, \"Epoch\"]).mean().groupby(param)\n",
    "else:\n",
    "    res_grouped = res.groupby([param1, param2, \"Epoch\"]).mean().groupby([param1, param2])\n",
    "\n",
    "display(res)\n",
    "display(res_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "# The results are saved in a pd dataframe with the following columns:\n",
    "#   - <hyperparam>: the value of hyperparameter that was tuned\n",
    "#   - Fold: the fold number\n",
    "#   - Epoch: the epoch number\n",
    "#   - Loss, Val loss: the training and validation loss\n",
    "#   - F1 score, Val F1 score: the training and validation F1 score\n",
    "\n",
    "if do_hyperparam_search:\n",
    "    if single_param_search:\n",
    "        # Single hyperparameter\n",
    "        res_grouped = res.groupby(param)\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        for param_value, group in res_grouped:\n",
    "            mean_group = group.groupby(\"Epoch\").mean(numeric_only=True)\n",
    "            min_group = group.groupby(\"Epoch\").min()\n",
    "            max_group = group.groupby(\"Epoch\").max()\n",
    "            \n",
    "            sns.lineplot(data=mean_group, x=\"Epoch\", y=\"Macro F1 score\",\n",
    "                         ax=ax[0], label=f\"{param}={param_value}\")\n",
    "            sns.lineplot(data=mean_group, x=\"Epoch\", y=\"Val Macro F1 score\",\n",
    "                         ax=ax[1], label=f\"{param}={param_value}\")\n",
    "\n",
    "            ax[0].fill_between(\n",
    "                mean_group.index, min_group[\"Macro F1 score\"], max_group[\"Macro F1 score\"], alpha=0.1)\n",
    "            ax[1].fill_between(\n",
    "                mean_group.index, min_group[\"Val Macro F1 score\"], max_group[\"Val Macro F1 score\"], alpha=0.1)\n",
    "            plt.ylim(0, 1)\n",
    "\n",
    "        # Plot average F1 score\n",
    "        ax[0].plot(res_grouped.mean()[\"Epoch\"], res_grouped.mean()[\n",
    "                   \"Macro F1 score\"], label=\"Average - train\", color='C1')\n",
    "        ax[1].plot(res_grouped.mean()[\"Epoch\"], res_grouped.mean()[\n",
    "                   \"Val Macro F1 score\"], label=\"Average - validation\", color='C1')\n",
    "\n",
    "        ax[0].set_title(f\"F1 score vs {param}\")\n",
    "        ax[1].set_title(f\"Validation F1 score vs {param}\")\n",
    "        fig.suptitle(study_id)\n",
    "    else:\n",
    "        # Two hyperparameters\n",
    "        # Mean the folds\n",
    "        res_grouped = res.groupby([param1, param2, \"Epoch\"]).mean().groupby([param1, param2])\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        max_f1 = res_grouped.max()['Val Macro F1 score'].unstack()\n",
    "        sns.heatmap(max_f1, annot=True, ax=ax[0], cmap='viridis')\n",
    "        ax[0].set_title(f\"{study_id} - Max Macro F1 score\")\n",
    "        ax[0].set_xlabel(param2)\n",
    "        ax[0].set_ylabel(param1)\n",
    "\n",
    "        # Plot of F1 over epochs for max of param 1\n",
    "        # Get the values of param1 and param2 that give max F1\n",
    "        max_p1 = max_f1.idxmax(axis=0)[values2[0]]\n",
    "\n",
    "\n",
    "        for param2_value in values2:\n",
    "            group = res_grouped.get_group((max_p1, param2_value))\n",
    "            mean_group = group.groupby(\"Epoch\").mean(numeric_only=True)\n",
    "            min_group = group.groupby(\"Epoch\").min(numeric_only=True)\n",
    "            max_group = group.groupby(\"Epoch\").max(numeric_only=True)\n",
    "            sns.lineplot(data=mean_group, x=\"Epoch\", y=\"Val Macro F1 score\",\n",
    "                         ax=ax[1], label=f\"{param2}={param2_value}\")\n",
    "        ax[1].set_title(f\"F1 score vs {param2} for {param1}={max_p1}\")\n",
    "\n",
    "        # Plot of F1 over epochs for max of param 2\n",
    "        max_p2 = max_f1.idxmax(axis=1)[values1[0]]\n",
    "\n",
    "        for param1_value in values1:\n",
    "            group = res_grouped.get_group((param1_value, max_p2))\n",
    "            mean_group = group.groupby(\"Epoch\").mean(numeric_only=True)\n",
    "            min_group = group.groupby(\"Epoch\").min(numeric_only=True)\n",
    "            max_group = group.groupby(\"Epoch\").max(numeric_only=True)\n",
    "            sns.lineplot(data=mean_group, x=\"Epoch\", y=\"Val Macro F1 score\",\n",
    "                         ax=ax[2], label=f\"{param1}={param1_value}\")\n",
    "            ax[2].fill_between(\n",
    "                mean_group.index, min_group[\"Val Macro F1 score\"], max_group[\"Val Macro F1 score\"], alpha=0.1)\n",
    "        ax[2].set_title(f\"F1 score vs {param1} for {param2}={max_p2}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "# We recreate the trainer object here in case we changed the hyperparams\n",
    "trainer = LabelTransferTrainer(hyperparams_file='hyperparams.csv',\n",
    "                            data_dir='exported_matrices',\n",
    "                            output_dir='label_transfer_model_output',\n",
    "                            verbose=False,\n",
    "                            random_seed=12345) \n",
    "    \n",
    "trainer.models[study_id], history = trainer.train_single_model(study_id)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "ax.flat[0].plot(history['loss'], label='train')\n",
    "ax.flat[0].plot(history['val_loss'], label='validation')\n",
    "ax.flat[0].set_xlabel('Epoch')\n",
    "ax.flat[0].set_ylabel('Loss')\n",
    "\n",
    "ax.flat[1].plot(history['macro_f1_score'], label='train')\n",
    "ax.flat[1].plot(history['val_macro_f1_score'], label='validation')\n",
    "ax.flat[1].set_xlabel('Epoch')\n",
    "ax.flat[1].set_ylabel('F1 score (macro)')\n",
    "\n",
    "ax.flat[2].plot(history['micro_f1_score'], label='train')\n",
    "ax.flat[2].plot(history['val_micro_f1_score'], label='validation')\n",
    "ax.flat[2].set_xlabel('Epoch')\n",
    "ax.flat[2].set_ylabel('F1 score (micro)')\n",
    "\n",
    "ax.flat[3].plot(history['ROCAUC'], label='train')\n",
    "ax.flat[3].plot(history['val_ROCAUC'], label='validation')\n",
    "ax.flat[3].set_xlabel('Epoch')\n",
    "ax.flat[3].set_ylabel('ROC AUC')\n",
    "\n",
    "plt.suptitle(f\"Training history for {study_id}\")\n",
    "\n",
    "for a in ax.flat[1:]:\n",
    "    a.set_ylim(0, 1.1)\n",
    "    a.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "trainer.evaluate_single_model(study_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "# We recreate the trainer object here in case we changed the hyperparams\n",
    "trainer = LabelTransferTrainer(hyperparams_file='hyperparams.csv',\n",
    "                            data_dir='exported_matrices',\n",
    "                            output_dir='label_transfer_model_output',\n",
    "                            verbose=False,\n",
    "                            random_seed=12345) \n",
    "\n",
    "# Uncomment to delete all saved model files\n",
    "trainer.clear_saved_models()\n",
    "trainer.train_all_models(reset_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(15, 15))\n",
    "\n",
    "dataset_names = [\n",
    "    f\"{d['author']} {d['year']} {d['sex']}\" for _, d in datasets.iterrows()]\n",
    "dataset_names = np.unique(dataset_names)\n",
    "hist_keys = list(trainer.training_histories.keys())\n",
    "\n",
    "for i, d in enumerate(dataset_names):\n",
    "    a = ax.ravel()[i]\n",
    "    a.plot(trainer.training_histories[hist_keys[i]]['macro_f1_score'])\n",
    "    a.plot(trainer.training_histories[hist_keys[i]]['val_macro_f1_score'])\n",
    "    a.set_title(d)\n",
    "    a.set_ylim([0, 1.1])\n",
    "    a.set_xlabel('Epoch')\n",
    "    a.set_ylabel('F1 score')\n",
    "\n",
    "ax.flat[-1].axis('off')\n",
    "ax.flat[-2].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_best_models()\n",
    "eval_res = trainer.evaluate_models()\n",
    "\n",
    "macro_f1 = [r[\"macro_f1_score\"] for r in eval_res.values()]\n",
    "micro_f1 = [r[\"micro_f1_score\"] for r in eval_res.values()]\n",
    "rocauc = [r[\"ROCAUC\"] for r in eval_res.values()]\n",
    "\n",
    "# barplot of the F1 scores, colored in red if the F1 score is below 0.5, yellow if below 0.8,\n",
    "# and green otherwise\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.barplot(x=list(eval_res.keys()), y=macro_f1,\n",
    "            palette=['red' if f < 0.5 else 'yellow' if f < 0.75 else 'green' for f in macro_f1],\n",
    "            ax=ax[0])\n",
    "ax[0].set_title('Macro F1 score')\n",
    "ax[0].set_ylabel('F1 score')\n",
    "for i, v in enumerate(macro_f1):\n",
    "    ax[0].text(i - 0.25, v + 0.01, f\"{v:.2f}\")\n",
    "\n",
    "sns.barplot(x=list(eval_res.keys()), y=micro_f1,\n",
    "            palette=['red' if f < 0.5 else 'yellow' if f < 0.75 else 'green' for f in micro_f1],\n",
    "            ax=ax[1])\n",
    "ax[1].set_title('Micro F1 score')\n",
    "ax[1].set_ylabel('F1 score')\n",
    "for i, v in enumerate(micro_f1):\n",
    "    ax[1].text(i - 0.25, v + 0.01, f\"{v:.2f}\")\n",
    "\n",
    "sns.barplot(x=list(eval_res.keys()), y=rocauc,\n",
    "            palette=['red' if f < 0.5 else 'yellow' if f < 0.75 else 'green' for f in rocauc],\n",
    "            ax=ax[2])\n",
    "ax[2].set_title('ROC AUC')\n",
    "ax[2].set_ylabel('ROC AUC')\n",
    "for i, v in enumerate(rocauc):\n",
    "    ax[2].text(i - 0.25, v + 0.01, f\"{v:.2f}\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_ylim([0, 1])\n",
    "    a.set_xticklabels(a.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# for f in macro_f1:\n",
    "#     print(f\"{f:.2f},\", end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean macro F1 score: {np.mean(macro_f1):.2f}\")\n",
    "print(f\"Median macro F1 score: {np.median(macro_f1):.2f}\")\n",
    "print(f\"Std macro F1 score: {np.std(macro_f1):.2f}\")\n",
    "print(\"*\" * 20)\n",
    "print(f\"Mean ROC AUC: {np.mean(rocauc):.2f}\")\n",
    "print(f\"Median ROC AUC: {np.median(rocauc):.2f}\")\n",
    "print(f\"Std ROC AUC: {np.std(rocauc):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = pd.DataFrame(trainer.load_best_models(clear_others=True))\n",
    "bm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single_cell_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
