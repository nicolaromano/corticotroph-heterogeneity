{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence Tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading expression matrices and labels for all male datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading expression matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 1182.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find all csv.gz files in the expr_matrices directory\n",
    "filenames_expr = [f for f in os.listdir(\"expr_matrices\") if f.endswith(\"M.csv.gz\")]\n",
    "filenames_clusters = [f for f in os.listdir(\"expr_matrices\") if f.endswith(\"M_clusters.csv\")]\n",
    "\n",
    "print(\"Reading expression matrices...\")\n",
    "expr = [pd.read_csv(f\"expr_matrices/{f}\") for f in tqdm(filenames_expr)]\n",
    "\n",
    "# Now intersect the gene ids\n",
    "common_genes = []\n",
    "for item in expr:\n",
    "    item.rename(columns={item.columns[0]: \"gene_id\"}, inplace = True)\n",
    "    item.set_index(\"gene_id\", inplace=True)\n",
    "    if len(common_genes) == 0:\n",
    "        common_genes = item.index\n",
    "    else:\n",
    "        common_genes = common_genes.intersection(item.index)\n",
    "\n",
    "for i in range(len(expr)):\n",
    "    expr[i] = expr[i].loc[common_genes]\n",
    "\n",
    "print(\"Reading clusters...\")\n",
    "clusters = [pd.read_csv(f\"expr_matrices/{f}\") for f in tqdm(filenames_clusters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines our MLP\n",
    "\n",
    "TODO: \n",
    "\n",
    "- hyperparameter tuning\n",
    "- regularization / dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_clusters:int) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build a 3-layer multi-class MLP classifier.\n",
    "    \n",
    "    param: n_clusters (int) - the number of clusters (possible classes)\n",
    "    return: model (keras.Model) - the model    \n",
    "    \"\"\"\n",
    "\n",
    "    # Now build our MLP\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=(len(common_genes))))\n",
    "    model.add(keras.layers.Dense(512, activation=\"relu\", name=\"hidden_1\"))\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\", name=\"hidden_2\"))\n",
    "    model.add(keras.layers.Dense(32, activation=\"relu\", name=\"hidden_3\"))\n",
    "    # Output layer\n",
    "    # Note the +1 to take into account the \"other\" class\n",
    "    model.add(keras.layers.Dense(n_clusters + 1, activation=\"softmax\", name=\"output\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prepares the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple expected at most 1 argument, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_training_data\u001b[39m(expr: \u001b[39mlist\u001b[39m, clusters: \u001b[39mlist\u001b[39m, dataset_id: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39;49m(np\u001b[39m.\u001b[39;49mndarray, np\u001b[39m.\u001b[39;49mndarray, np\u001b[39m.\u001b[39;49mndarray, np\u001b[39m.\u001b[39;49mndarray):\n\u001b[1;32m      <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=1'>2</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39m    Prepare the training data for the MLP.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=3'>4</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=8'>9</a>\u001b[0m \u001b[39m    return: y_train (np.array) - the training labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=9'>10</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=11'>12</a>\u001b[0m     \u001b[39m# We will use the expression matrices as the training data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=12'>13</a>\u001b[0m     \u001b[39m# The labels will be the cluster labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=13'>14</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/storage/Storage/Nico/scRNAseqPit/08_transfer_learning.ipynb#ch0000010?line=14'>15</a>\u001b[0m     \u001b[39m# We get the expression matrix and labels for the dataset we are using as reference...\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple expected at most 1 argument, got 4"
     ]
    }
   ],
   "source": [
    "def prepare_training_data(expr: List, clusters: List, dataset_id: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Prepare the training data for the MLP.\n",
    "\n",
    "    param: expr (list) - the expression matrices\n",
    "    param: clusters (list) - the list of cluster identities\n",
    "    param: dataset_id (int) - the id of the dataset we are using as reference\n",
    "    return: x_train (np.array) - the training data\n",
    "    return: y_train (np.array) - the training labels\n",
    "    \"\"\"\n",
    "\n",
    "    # We will use the expression matrices as the training data\n",
    "    # The labels will be the cluster labels\n",
    "\n",
    "    # We get the expression matrix and labels for the dataset we are using as reference...\n",
    "    expr = expr[dataset_id]\n",
    "    clusters = clusters[dataset_id]\n",
    "    # ... and split into training and test data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(expr, clusters, test_size=0.1, random_state=42)\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=len(clusters) + 1)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=len(clusters) + 1)\n",
    "\n",
    "    return (x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_1 (Dense)            (None, 512)               6248960   \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 32)                8224      \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,388,743\n",
      "Trainable params: 6,388,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ref_dataset = 3\n",
    "\n",
    "model  = build_model(len(clusters[ref_dataset][\"Cluster\"].unique()))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('image_analysis_3_10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec56b008a282d9e3f7d97665e7b2fb5c20f951cff21dcda9c5319bc9d0609467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
